{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "class FrequencySummarizer:\n",
    "    def __init__(self, min_cut=0.1, max_cut=0.9):\n",
    "        \"\"\"\n",
    "        Initilize the text summarizer.\n",
    "        Words that have a frequency term lower than min_cut \n",
    "        or higer than max_cut will be ignored.\n",
    "        \"\"\"\n",
    "        self._min_cut = min_cut\n",
    "        self._max_cut = max_cut \n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "    \n",
    "    def _compute_frequencies(self, word_sent):\n",
    "        \"\"\" \n",
    "        Compute the frequency of each of word.\n",
    "        Input: \n",
    "        word_sent, a list of sentences already tokenized.\n",
    "        Output: \n",
    "        freq, a dictionary where freq[w] is the frequency of w.\n",
    "        \"\"\"\n",
    "        freq = defaultdict(int)\n",
    "        for s in word_sent:\n",
    "            for word in s:\n",
    "                if word not in self._stopwords:\n",
    "                      freq[word] += 1\n",
    "        # frequencies normalization and fitering\n",
    "        m = float(max(freq.values()))\n",
    "        keys=list(freq.keys())\n",
    "        for w in keys:\n",
    "            freq[w]=freq[w]/m\n",
    "            if freq[w]>=0.9 or freq[w]<=0.1:\n",
    "                keys.remove(w)\n",
    "        freq=dict((k,v) for k,v in freq.items() if k in keys)\n",
    "        return freq\n",
    "\n",
    "    def summarize(self, text, n):\n",
    "        \"\"\"\n",
    "        Return a list of n sentences \n",
    "        which represent the summary of text.\n",
    "        \"\"\"\n",
    "        sents = sent_tokenize(text)\n",
    "        assert n <= len(sents)\n",
    "        word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "        self._freq = self._compute_frequencies(word_sent)\n",
    "        ranking = defaultdict(int)\n",
    "        for i,sent in enumerate(word_sent):\n",
    "            for w in sent:\n",
    "                if w in self._freq:\n",
    "                    ranking[i] += self._freq[w]\n",
    "        sents_idx = self._rank(ranking, n)    \n",
    "        return [sents[j] for j in sents_idx]\n",
    "\n",
    "    def _rank(self, ranking, n):\n",
    "        \"\"\" return the first n sentences with highest ranking \"\"\"\n",
    "        return nlargest(n, ranking, key=ranking.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://stackoverflow.com/questions/38635419/searching-in-google-with-python'\n",
    "html=urllib.request.urlopen(url)\n",
    "soup=BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=' '.join(map(lambda p: p.text,soup.find_all('p')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Or I did work out with selenium web driver and it works great if used with Firefox or chrome or Phantom web browser, but still I felt it was a bit slow in terms of execution time, as it queried browser first and then returned search result.',\n",
       " 'asked 1 year, 7 months ago viewed \\n18,264 times\\n active 14 days ago \\r\\nsite design / logo © 2018 Stack Exchange Inc; user contributions licensed under cc by-sa 3.0\\r\\n                            with attribution required.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs=FrequencySummarizer()\n",
    "fs.summarize(text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sents=sent_tokenize(text)\n",
    "word_sent=[word_tokenize(s.lower()) for s in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq=defaultdict(int)\n",
    "for s in word_sent:\n",
    "    for word in s:\n",
    "        if word not in set(stopwords.words('english') + list(punctuation)):\n",
    "            freq[word]+=1\n",
    "m=float(max(freq.values()))\n",
    "keys=list(freq.keys())\n",
    "for w in keys:\n",
    "    freq[w]=freq[w]/m\n",
    "    if freq[w]>=0.9 or freq[w]<=0.1:\n",
    "        keys.remove(w)\n",
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq=dict((k,v) for k,v in freq.items() if k in keys)\n",
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking=defaultdict(int)\n",
    "for i, sent in enumerate(word_sent):\n",
    "    for w in sent:\n",
    "        if w in freq:\n",
    "            ranking[i]+=freq[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys=freq.keys()\n",
    "#list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_idx=nlargest(2, ranking, key=ranking.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nPost\\n\\nby Bosvark » Thu Nov 13, 2014 2:38 pm\\n\\t\\t\\t \\n\\nPost\\n\\nby Decker_MMIV » Thu Nov 13, 2014 5:43 pm\\n\\t\\t\\t \\n\\nReturn to “[LS15]English-Forum”']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sents[j] for j in sents_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Searching in Google with Python - Stack Overflow'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.pinterest.com/pin/552535448014491439/'\n",
    "html=urllib.request.urlopen(url)\n",
    "soup=BeautifulSoup(html,'lxml')\n",
    "text=' '.join(map(lambda p: p.text,soup.find_all('p')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have dill growing in all of my flower beds! <em>Calamintha nepeta</em> An important aromatic and antiseptic herb in native North American medicine, the light brownish flowers of Western mugwort are bourne in panicles in late summer and the leaves act as a good deodorant in shoes. It thrives in sandy soil. Golden Oregano is milder than Italian or Greek oregano, but what it lacks in flavor it makes up in beauty: It's an excellent groundcover with small pink or purple flowers in summer. <em>Tanacetum balsamita</em> Alchemilla alpina It is easy to grow and compact in form, but it self-seeds and hybridizes readily. Height: inches Spread: 20 inches Hardiness: Fully hardy plants Soil Preference: Moist soil Sun or Shade: Full sun, partial or dappled shade Check out our complete guide to herbs from Ac to He.\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<em>Calamintha nepeta</em> An important aromatic and antiseptic herb in native North American medicine, the light brownish flowers of Western mugwort are bourne in panicles in late summer and the leaves act as a good deodorant in shoes.',\n",
       " 'Height: inches Spread: 20 inches Hardiness: Fully hardy plants Soil Preference: Moist soil Sun or Shade: Full sun, partial or dappled shade Check out our complete guide to herbs from Ac to He.',\n",
       " \"Golden Oregano is milder than Italian or Greek oregano, but what it lacks in flavor it makes up in beauty: It's an excellent groundcover with small pink or purple flowers in summer.\",\n",
       " '<em>Tanacetum balsamita</em> Alchemilla alpina It is easy to grow and compact in form, but it self-seeds and hybridizes readily.',\n",
       " 'I have dill growing in all of my flower beds!']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs=FrequencySummarizer()\n",
    "fs.summarize(text,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
